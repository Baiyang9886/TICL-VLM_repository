# Task Incremental Continual Learning Based on Language Prompt Feature Selection and Pre-trained Visual-language Modle

Visual-language models (VLMs) bridge the gap between the visual and language modalities, allowing humans to pass some prior experience to the model in the form of language, thereby guiding the model to complete visual tasks more accurately and efficiently. VLMs provide a new way for the field of task incremental continuous learning. They enable us to guide the model to focus on target features through textual description of task prompts. Therefore, in this study, we propose a task incremental continual learning method based on the VLM (TICL-VLM). This method allows the model to accumulate knowledge and become stronger and stronger by learning continuously, like humans. Moreover, the computational overhead of this method is not very high, making it with great potential for practical applications. 
